{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "respondents = pd.read_csv(os.path.join('..', 'data', 'raw', 'raw_respondents.csv'), index_col=0)\n",
    "results = pd.read_csv(os.path.join('..', 'data', 'raw', 'raw_results.csv'), index_col=0)\n",
    "_, _, cardsE, cardsB = loadData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Respondents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRT calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "respondents['crt'] = 0\n",
    "respondents.loc[respondents.crt1 == '5 pence', 'crt'] += 1\n",
    "respondents.loc[respondents.crt2 == '5 minutes', 'crt'] += 1\n",
    "respondents.loc[respondents.crt3 == '47 days', 'crt'] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CRT check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crtCheck\n",
       "No     100\n",
       "Yes     60\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respondents.crtCheck.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all of them, honestly. \n",
      "During a past survey I did, these questions were present.\n",
      "MQ3 about the lily pads \n",
      "All of them.\n",
      "All three questions many times over the last five to ten years, I couldn't say when I first encountered them\n",
      "lilly pad\n",
      "All three of them I have encountered previously\n",
      "All of them, although I can't say precisely where.\n",
      "I've seen a variation of the lily pad question\n",
      "The bat and ball question\n",
      "All 3\n",
      "All three were in a work quiz\n",
      "The bat and ball, and the lily pads in the lake\n",
      "I have been asked the exact same three questions multiple times. \n",
      "The bat and the ball one is a frequent one I've seen.\n",
      "The first one - though im not sure where\n",
      "nan\n",
      "Bat & Ball definitely and im sure the lily pads but cannot remember the answer.\n",
      "MQ3: In a lake, there is a patch of lily pads. Every day, the patch doubles in size. If it takes 48 days for the patch to cover the entire lake, how long would it take for the patch to cover half of the lake? *\n",
      "\n",
      "I have encountered similar questions to all 3 of them before.\n",
      "All three of them.\n",
      "They seem familiar but I still don't know the answers!\n",
      "All of them, is it a standard set for studies/tests?\n",
      "MQ1 and MQ2 \n",
      "ive encountered all 3 of them numerous times\n",
      "If it takes 5 machines 5 minutes to make 5 widgets, how long would it take 100 machines to make 100 widgets? This is a very common question in some tests. The others I have not seen before. \n",
      "i have encountered all three of them before\n",
      "all of them\n",
      "the lily pad question\n",
      "MQ1, MQ3\n",
      "all three\n",
      "MQ3\n",
      "All of them\n",
      "all 3 doing other surveys\n",
      "I have encountered all of them before and I know the questions target our biases.\n",
      "I have encountered the bat and ball question before.\n",
      "All of the above.\n",
      "MQ3\n",
      "All of the questions I have encountered either in class quizes or pubs or among friends. \n",
      "I think I've seen MQ1 before; it feels familiar.\n",
      "All three.\n",
      "lily pad one\n",
      "I have encountered all three questions in previous studies, as well as variations of them in general quizzes (such as Christmas quizzes) as well as when I was in full time education.\n",
      "I have seen all 3 mathematical questions before.\n",
      "M2 the machine and widgets\n",
      "MQ1 and MQ3\n",
      "I seem to remember the question about the lily pads\n",
      "all 3 of them\n",
      "They are all commonly used questions.\n",
      "only the bat and the ball one\n",
      "the ball and bat question\n",
      "all of them\n",
      "All 3\n",
      "The one about the bat and ball has been on a different survey a very long time ago I think.\n",
      "All of them, standard cognitive questions\n",
      "nan\n",
      "i have encountered all 3 of these questions in the past on various logic tests\n",
      "All three mathematical questions in a previous survey.\n",
      "all\n",
      "The ball and the bat, and the widgets.\n",
      "All of them\n",
      "All of them\n"
     ]
    }
   ],
   "source": [
    "for i in respondents.crtCheckElaborate[respondents.crtCheckElaborate != 'Did not answer'].values:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.42771019398377813)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respondents.crt.corr(respondents.crtCheck.apply(lambda x: 0 if x == 'No' else 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crtCheck</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>1.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.128644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>2.25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.083388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean  median       std\n",
       "crtCheck                        \n",
       "No        1.17     1.0  1.128644\n",
       "Yes       2.25     3.0  1.083388"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respondents.groupby('crtCheck').crt.agg(['mean', 'median', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=np.float64(4484.0), pvalue=np.float64(5.309013691076753e-08))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mannwhitneyu(respondents[respondents.crtCheck == 'Yes'].crt, respondents[respondents.crtCheck == 'No'].crt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big 5 calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "respondents['bfExtra'] = 0\n",
    "respondents.bfExtra += (6 - respondents.bf1) + respondents.bf6 + respondents.bf11\n",
    "\n",
    "respondents['bfAgree'] = 0\n",
    "respondents.bfAgree += respondents.bf2 + (6 - respondents.bf7) + respondents.bf12\n",
    "\n",
    "respondents['bfConsc'] = 0\n",
    "respondents.bfConsc += (6 - respondents.bf3) + (6 - respondents.bf8) + respondents.bf13\n",
    "\n",
    "respondents['bfNegEmo'] = 0\n",
    "respondents.bfNegEmo += respondents.bf4 + respondents.bf9 + (6 - respondents.bf14)\n",
    "\n",
    "respondents['bfOpenMind'] = 0\n",
    "respondents.bfOpenMind += respondents.bf5 + (6 - respondents.bf10) + respondents.bf15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Straightlining check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E50 26 0.40952380952380957\n",
      "E50 37 0.5714285714285714\n",
      "E50 39 0.20952380952380958\n",
      "E30 22 0.42857142857142855\n",
      "E30 23 0.5523809523809524\n",
      "E30 36 0.5523809523809524\n",
      "B50 6 0.5714285714285714\n",
      "B50 30 0.5523809523809524\n",
      "B50 40 0.5428571428571429\n",
      "B30 22 0.49523809523809514\n"
     ]
    }
   ],
   "source": [
    "for index, row in respondents[['respondent', 'variant', 'bf1', 'bf2', 'bf3', 'bf4', 'bf5', 'bf6', \n",
    "                               'bf7', 'bf8', 'bf9', 'bf10', 'bf11', 'bf12', 'bf13', 'bf14', 'bf15']].iterrows():\n",
    "    if(row[2:17].var() < 0.6):\n",
    "        print(row.variant, row.respondent, row[2:17].var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "respondents.time = respondents.time.apply(lambda x: int(x.split(':')[0]) * 60 * 60 + int(x.split(':')[1]) * 60 + int(x.split(':')[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "respondents = respondents[[\n",
    "    'respondent', 'variant', 'time', 'categories', 'age', 'gender',\n",
    "    'education', 'income', 'domain', 'crt', 'labelClarity', 'sortDifficulty',\n",
    "    'concentration', 'timeAmount', 'cardQuantity', 'bfExtra', 'bfAgree', \n",
    "    'bfConsc', 'bfNegEmo', 'bfOpenMind', 'att1', 'att2', 'note'\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results[['respondent', 'card', 'category', 'categoryId', 'categoryStandardized',\n",
    "       'order', 'variant']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories as keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['categoryEdited'] = results.category.str.lower()\n",
    "results['categoryEdited'] = results.categoryEdited.apply(lambda x: x.strip())\n",
    "results['categoryEdited'] = results.categoryEdited.apply(lambda x: re.sub('[.&,\\'/,()+!#]|( - )', ' ', x))\n",
    "results['categoryEdited'] = results.categoryEdited.apply(lambda x: ' '.join(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in respondents.iterrows():\n",
    "    cats = results[(results.variant==row.variant) & (results.respondent==row.respondent)].categoryEdited.unique()\n",
    "    respondents.loc[index, 'informativeness'] = informativeness(' '.join(cats)) / len(cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `makeMatrix()` and `BMM()` in the `utils.ipynb` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in ['paired', 'seen', 'similarity', 'similarityAbsolute', 'C-similarity', 'C-similarityAbsolute']:\n",
    "    for v in ['E50', 'E30', 'B50', 'B30']:\n",
    "        if(v in ['E50', 'E30']):\n",
    "            dataF = makeMatrix(m, results[results.variant==v], cardsE, 40)\n",
    "        if(v in ['B50', 'B30']):\n",
    "            dataF = makeMatrix(m, results[results.variant==v], cardsB, 40)\n",
    "        dataF.to_csv(os.path.join('..', 'data', 'matrices', m + v + '.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agreement scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variant in ['E50', 'E30', 'B50', 'B30']:\n",
    "    for index, group in results[results.variant==variant].groupby('categoryStandardized'):\n",
    "        if(len(group.categoryId.unique())!=1):\n",
    "            cards = {}\n",
    "            cats = 0\n",
    "            resps = len(group.respondent.unique())\n",
    "            for jndex, jgroup in group.groupby(['respondent', 'categoryId']):\n",
    "                cats += 1\n",
    "                for kndex, row in jgroup.iterrows():\n",
    "                    cards[row.card] = 1 if row.card not in cards else cards[row.card] + 1\n",
    "            x = list(map(lambda x: x/len(cards.values()) *100, cards.values()))\n",
    "            a = sum(x)/resps\n",
    "            results.loc[(results.variant==variant) & (results.categoryStandardized==index), 'agreement'] = a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Author duplicates check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = (\n",
    "    results.groupby(['variant', 'categoryStandardized', 'respondent'])\n",
    "           .categoryId.nunique()\n",
    "           .reset_index(name='unique_categories')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variant\n",
       "B30     3.296703\n",
       "B50     5.376344\n",
       "E30    11.864407\n",
       "E50    15.384615\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(duplicates[duplicates.unique_categories > 1].groupby('variant')['categoryStandardized'].nunique() / results.groupby(['variant', 'categoryStandardized']).size().reset_index().groupby('variant').size() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "respondents.to_csv(os.path.join('..', 'data', 'respondents.csv'))\n",
    "results.to_csv(os.path.join('..', 'data', 'results.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
